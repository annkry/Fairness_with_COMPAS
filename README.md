# Fairness_with_COMPAS
  
Analyzed biases in the COMPAS risk assessment tool, trained various classifiers to predict recidivism, and developed a fair classification model to address identified biases. This project involved thorough data analysis, model development, and the application of fairness metrics, providing a comprehensive understanding of ethical considerations in machine learning.
